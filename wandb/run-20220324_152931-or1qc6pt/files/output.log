<xml><var name="DataFrame" type="type" qualifier="builtins" value="%3Cclass %27pandas.core.frame.DataFrame%27&gt;" isContainer="True" />
<var name="In" type="list" qualifier="builtins" value="%5B%27%27%2C %27import torch%5Cnfrom d2l import torch as d2l%5Cnfrom torch import nn%5Cn%5Cnimport wandb%5Cn%5Cnwandb.init%28project=%22my-test-project%22%2C entity=%22j1feng%22%29%5Cnwandb.config = %7B%5Cn    %22learning_rate%22%3A 0.1%2C%5Cn    %22epochs%22%3A 10%2C%5Cn    %22batch_size%22%3A 256%5Cn%7D%5Cn%5Cnbatch_size = 256%5Cntrain_iter%2C test_iter = d2l.load_data_fashion_mnist%28batch_size%29%27%2C %27%23 PyTorch%E4%B8%8D%E4%BC%9A%E9%9A%90%E5%BC%8F%E5%9C%B0%E8%B0%83%E6%95%B4%E8%BE%93%E5%85%A5%E7%9A%84%E5%BD%A2%E7%8A%B6%E3%80%82%E5%9B%A0%E6%AD%A4%EF%BC%8C%5Cn%23 %E6%88%91%E4%BB%AC%E5%9C%A8%E7%BA%BF%E6%80%A7%E5%B1%82%E5%89%8D%E5%AE%9A%E4%B9%89%E4%BA%86%E5%B1%95%E5%B9%B3%E5%B1%82%EF%BC%88flatten%EF%BC%89%EF%BC%8C%E6%9D%A5%E8%B0%83%E6%95%B4%E7%BD%91%E7%BB%9C%E8%BE%93%E5%85%A5%E7%9A%84%E5%BD%A2%E7%8A%B6%5Cnnet = nn.Sequential%28nn.Flatten%28%29%2C nn.Linear%28784%2C 10%29%29%5Cn%5Cn%5Cndef init_weights%28m%29%3A%5Cn    if type%28m%29 == nn.Linear%3A%5Cn        nn.init.normal_%28m.weight%2C std=0.01%29%5Cn%5Cn%5Cnnet.apply%28init_weights%29%3B%27%2C %22loss = nn.CrossEntropyLoss%28reduction=%27none%27%29%22%2C %27trainer = torch.optim.SGD%28net.parameters%28%29%2C lr=0.1%29%27%2C %27num_epochs = 10%5Cnd2l.train_ch3%28net%2C train_iter%2C test_iter%2C loss%2C num_epochs%2C trainer%29%27%2C %27wandb.log%28%7B%22loss%22%3A loss%7D%29%5Cn%5Cn%23 Optional%5Cnwandb.watch%28net%29%27%2C %27wandb.log%28%7B%22loss%22%3A loss%7D%29%5Cn%5Cn%23 Optional%5Cnwandb.watch%28net%2C log=%5C%27all%5C%27%29%27%2C %27wandb.log%28%7B%22loss%22%3A loss%7D%29%5Cn%5Cn%23 Optional%5Cnwandb.watch%28net%2C log=%5C%27all%5C%27%29%5Cntype%28net%29%27%2C %27import torch%5C..." isContainer="True" shape="14" isIPythonHidden="True" />
<var name="MultiIndex" type="type" qualifier="builtins" value="%3Cclass %27pandas.core.indexes.multi.MultiIndex%27&gt;" isContainer="True" />
<var name="Out" type="dict" qualifier="builtins" value="%7B6%3A %5B%5D%2C 7%3A %5B%5D%2C 8%3A %3Cclass %27torch.nn.modules.container.Sequential%27&gt;%7D" isContainer="True" shape="3" isIPythonHidden="True" />
<var name="_" type="type" qualifier="builtins" value="%3Cclass %27torch.nn.modules.container.Sequential%27&gt;" isContainer="True" isIPythonHidden="True" />
<var name="_6" type="list" qualifier="builtins" value="%5B%5D" isContainer="True" shape="0" isIPythonHidden="True" />
<var name="_7" type="list" qualifier="builtins" value="%5B%5D" isContainer="True" shape="0" isIPythonHidden="True" />
<var name="_8" type="type" qualifier="builtins" value="%3Cclass %27torch.nn.modules.container.Sequential%27&gt;" isContainer="True" isIPythonHidden="True" />
<var name="__" type="list" qualifier="builtins" value="%5B%5D" isContainer="True" shape="0" isIPythonHidden="True" />
<var name="___" type="list" qualifier="builtins" value="%5B%5D" isContainer="True" shape="0" isIPythonHidden="True" />
<var name="__builtin__" type="module" qualifier="builtins" value="%3Cmodule %27builtins%27 %28built-in%29&gt;" isContainer="True" isIPythonHidden="True" />
<var name="__builtins__" type="module" qualifier="builtins" value="%3Cmodule %27builtins%27 %28built-in%29&gt;" isContainer="True" isIPythonHidden="True" />
<var name="__doc__" type="str" qualifier="builtins" value="Automatically created module for IPython interactive environment" isIPythonHidden="True" />
<var name="__loader__" type="NoneType" qualifier="builtins" value="None" isIPythonHidden="True" />
<var name="__name__" type="str" qualifier="builtins" value="__main__" isIPythonHidden="True" />
<var name="__package__" type="NoneType" qualifier="builtins" value="None" isIPythonHidden="True" />
<var name="__spec__" type="NoneType" qualifier="builtins" value="None" isIPythonHidden="True" />
<var name="_dh" type="list" qualifier="builtins" value="%5B%27E%3A%5C%5CAI_project%27%5D" isContainer="True" shape="1" isIPythonHidden="True" />
<var name="_i" type="str" qualifier="builtins" value="trainer = torch.optim.SGD%28net.parameters%28%29%2C lr=0.1%29" isIPythonHidden="True" />
<var name="_i1" type="str" qualifier="builtins" value="import torch%0Afrom d2l import torch as d2l%0Afrom torch import nn%0A%0Aimport wandb%0A%0Awandb.init%28project=%22my-test-project%22%2C entity=%22j1feng%22%29%0Awandb.config = %7B%0A    %22learning_rate%22%3A 0.1%2C%0A    %22epochs%22%3A 10%2C%0A    %22batch_size%22%3A 256%0A%7D%0A%0Abatch_size = 256%0Atrain_iter%2C test_iter = d2l.load_data_fashion_mnist%28batch_size%29" isIPythonHidden="True" />
<var name="_i10" type="str" qualifier="builtins" value="%23 PyTorch%E4%B8%8D%E4%BC%9A%E9%9A%90%E5%BC%8F%E5%9C%B0%E8%B0%83%E6%95%B4%E8%BE%93%E5%85%A5%E7%9A%84%E5%BD%A2%E7%8A%B6%E3%80%82%E5%9B%A0%E6%AD%A4%EF%BC%8C%0A%23 %E6%88%91%E4%BB%AC%E5%9C%A8%E7%BA%BF%E6%80%A7%E5%B1%82%E5%89%8D%E5%AE%9A%E4%B9%89%E4%BA%86%E5%B1%95%E5%B9%B3%E5%B1%82%EF%BC%88flatten%EF%BC%89%EF%BC%8C%E6%9D%A5%E8%B0%83%E6%95%B4%E7%BD%91%E7%BB%9C%E8%BE%93%E5%85%A5%E7%9A%84%E5%BD%A2%E7%8A%B6%0Anet = nn.Sequential%28nn.Flatten%28%29%2C nn.Linear%28784%2C 10%29%29%0A%0A%0Adef init_weights%28m%29%3A%0A    if type%28m%29 == nn.Linear%3A%0A        nn.init.normal_%28m.weight%2C std=0.01%29%0A%0A%0Anet.apply%28init_weights%29%3B" isIPythonHidden="True" />
<var name="_i11" type="str" qualifier="builtins" value="loss = nn.CrossEntropyLoss%28reduction=%27none%27%29" isIPythonHidden="True" />
<var name="_i12" type="str" qualifier="builtins" value="trainer = torch.optim.SGD%28net.parameters%28%29%2C lr=0.1%29" isIPythonHidden="True" />
<var name="_i13" type="str" qualifier="builtins" value="num_epochs = 10%0Ad2l.train_ch3%28net%2C train_iter%2C test_iter%2C loss%2C num_epochs%2C trainer%29" isIPythonHidden="True" />
<var name="_i2" type="str" qualifier="builtins" value="%23 PyTorch%E4%B8%8D%E4%BC%9A%E9%9A%90%E5%BC%8F%E5%9C%B0%E8%B0%83%E6%95%B4%E8%BE%93%E5%85%A5%E7%9A%84%E5%BD%A2%E7%8A%B6%E3%80%82%E5%9B%A0%E6%AD%A4%EF%BC%8C%0A%23 %E6%88%91%E4%BB%AC%E5%9C%A8%E7%BA%BF%E6%80%A7%E5%B1%82%E5%89%8D%E5%AE%9A%E4%B9%89%E4%BA%86%E5%B1%95%E5%B9%B3%E5%B1%82%EF%BC%88flatten%EF%BC%89%EF%BC%8C%E6%9D%A5%E8%B0%83%E6%95%B4%E7%BD%91%E7%BB%9C%E8%BE%93%E5%85%A5%E7%9A%84%E5%BD%A2%E7%8A%B6%0Anet = nn.Sequential%28nn.Flatten%28%29%2C nn.Linear%28784%2C 10%29%29%0A%0A%0Adef init_weights%28m%29%3A%0A    if type%28m%29 == nn.Linear%3A%0A        nn.init.normal_%28m.weight%2C std=0.01%29%0A%0A%0Anet.apply%28init_weights%29%3B" isIPythonHidden="True" />
<var name="_i3" type="str" qualifier="builtins" value="loss = nn.CrossEntropyLoss%28reduction=%27none%27%29" isIPythonHidden="True" />
<var name="_i4" type="str" qualifier="builtins" value="trainer = torch.optim.SGD%28net.parameters%28%29%2C lr=0.1%29" isIPythonHidden="True" />
<var name="_i5" type="str" qualifier="builtins" value="num_epochs = 10%0Ad2l.train_ch3%28net%2C train_iter%2C test_iter%2C loss%2C num_epochs%2C trainer%29" isIPythonHidden="True" />
<var name="_i6" type="str" qualifier="builtins" value="wandb.log%28%7B%22loss%22%3A loss%7D%29%0A%0A%23 Optional%0Awandb.watch%28net%29" isIPythonHidden="True" />
<var name="_i7" type="str" qualifier="builtins" value="wandb.log%28%7B%22loss%22%3A loss%7D%29%0A%0A%23 Optional%0Awandb.watch%28net%2C log=%27all%27%29" isIPythonHidden="True" />
<var name="_i8" type="str" qualifier="builtins" value="wandb.log%28%7B%22loss%22%3A loss%7D%29%0A%0A%23 Optional%0Awandb.watch%28net%2C log=%27all%27%29%0Atype%28net%29" isIPythonHidden="True" />
<var name="_i9" type="str" qualifier="builtins" value="import torch%0Afrom d2l import torch as d2l%0Afrom torch import nn%0A%0Aimport wandb%0A%0Awandb.init%28project=%22my-test-project%22%2C entity=%22j1feng%22%29%0Awandb.config = %7B%0A    %22learning_rate%22%3A 0.1%2C%0A    %22epochs%22%3A 10%2C%0A    %22batch_size%22%3A 256%0A%7D%0A%0Abatch_size = 256%0Atrain_iter%2C test_iter = d2l.load_data_fashion_mnist%28batch_size%29" isIPythonHidden="True" />
<var name="_ih" type="list" qualifier="builtins" value="%5B%27%27%2C %27import torch%5Cnfrom d2l import torch as d2l%5Cnfrom torch import nn%5Cn%5Cnimport wandb%5Cn%5Cnwandb.init%28project=%22my-test-project%22%2C entity=%22j1feng%22%29%5Cnwandb.config = %7B%5Cn    %22learning_rate%22%3A 0.1%2C%5Cn    %22epochs%22%3A 10%2C%5Cn    %22batch_size%22%3A 256%5Cn%7D%5Cn%5Cnbatch_size = 256%5Cntrain_iter%2C test_iter = d2l.load_data_fashion_mnist%28batch_size%29%27%2C %27%23 PyTorch%E4%B8%8D%E4%BC%9A%E9%9A%90%E5%BC%8F%E5%9C%B0%E8%B0%83%E6%95%B4%E8%BE%93%E5%85%A5%E7%9A%84%E5%BD%A2%E7%8A%B6%E3%80%82%E5%9B%A0%E6%AD%A4%EF%BC%8C%5Cn%23 %E6%88%91%E4%BB%AC%E5%9C%A8%E7%BA%BF%E6%80%A7%E5%B1%82%E5%89%8D%E5%AE%9A%E4%B9%89%E4%BA%86%E5%B1%95%E5%B9%B3%E5%B1%82%EF%BC%88flatten%EF%BC%89%EF%BC%8C%E6%9D%A5%E8%B0%83%E6%95%B4%E7%BD%91%E7%BB%9C%E8%BE%93%E5%85%A5%E7%9A%84%E5%BD%A2%E7%8A%B6%5Cnnet = nn.Sequential%28nn.Flatten%28%29%2C nn.Linear%28784%2C 10%29%29%5Cn%5Cn%5Cndef init_weights%28m%29%3A%5Cn    if type%28m%29 == nn.Linear%3A%5Cn        nn.init.normal_%28m.weight%2C std=0.01%29%5Cn%5Cn%5Cnnet.apply%28init_weights%29%3B%27%2C %22loss = nn.CrossEntropyLoss%28reduction=%27none%27%29%22%2C %27trainer = torch.optim.SGD%28net.parameters%28%29%2C lr=0.1%29%27%2C %27num_epochs = 10%5Cnd2l.train_ch3%28net%2C train_iter%2C test_iter%2C loss%2C num_epochs%2C trainer%29%27%2C %27wandb.log%28%7B%22loss%22%3A loss%7D%29%5Cn%5Cn%23 Optional%5Cnwandb.watch%28net%29%27%2C %27wandb.log%28%7B%22loss%22%3A loss%7D%29%5Cn%5Cn%23 Optional%5Cnwandb.watch%28net%2C log=%5C%27all%5C%27%29%27%2C %27wandb.log%28%7B%22loss%22%3A loss%7D%29%5Cn%5Cn%23 Optional%5Cnwandb.watch%28net%2C log=%5C%27all%5C%27%29%5Cntype%28net%29%27%2C %27import torch%5C..." isContainer="True" shape="14" isIPythonHidden="True" />
<var name="_ii" type="str" qualifier="builtins" value="loss = nn.CrossEntropyLoss%28reduction=%27none%27%29" isIPythonHidden="True" />
<var name="_iii" type="str" qualifier="builtins" value="%23 PyTorch%E4%B8%8D%E4%BC%9A%E9%9A%90%E5%BC%8F%E5%9C%B0%E8%B0%83%E6%95%B4%E8%BE%93%E5%85%A5%E7%9A%84%E5%BD%A2%E7%8A%B6%E3%80%82%E5%9B%A0%E6%AD%A4%EF%BC%8C%0A%23 %E6%88%91%E4%BB%AC%E5%9C%A8%E7%BA%BF%E6%80%A7%E5%B1%82%E5%89%8D%E5%AE%9A%E4%B9%89%E4%BA%86%E5%B1%95%E5%B9%B3%E5%B1%82%EF%BC%88flatten%EF%BC%89%EF%BC%8C%E6%9D%A5%E8%B0%83%E6%95%B4%E7%BD%91%E7%BB%9C%E8%BE%93%E5%85%A5%E7%9A%84%E5%BD%A2%E7%8A%B6%0Anet = nn.Sequential%28nn.Flatten%28%29%2C nn.Linear%28784%2C 10%29%29%0A%0A%0Adef init_weights%28m%29%3A%0A    if type%28m%29 == nn.Linear%3A%0A        nn.init.normal_%28m.weight%2C std=0.01%29%0A%0A%0Anet.apply%28init_weights%29%3B" isIPythonHidden="True" />
<var name="_oh" type="dict" qualifier="builtins" value="%7B6%3A %5B%5D%2C 7%3A %5B%5D%2C 8%3A %3Cclass %27torch.nn.modules.container.Sequential%27&gt;%7D" isContainer="True" shape="3" isIPythonHidden="True" />
<var name="_pydevd_bundle" type="module" qualifier="builtins" value="%3Cmodule %27_pydevd_bundle%27 from %27E%3A%5C%5CPyCharm 2021.3%5C%5Cplugins%5C%5Cpython%5C%5Chelpers%5C%5Cpydev%5C%5C_pydevd_bundle%5C%5C__init__.py%27&gt;" isContainer="True" />
<var name="batch_size" type="int" qualifier="builtins" value="256" />
<var name="d2l" type="module" qualifier="builtins" value="%3Cmodule %27d2l.torch%27 from %27E%3A%5C%5Cana%5C%5Clib%5C%5Csite-packages%5C%5Cd2l%5C%5Ctorch.py%27&gt;" isContainer="True" />
<var name="exit" type="ZMQExitAutocall" qualifier="IPython.core.autocall" value="%3CIPython.core.autocall.ZMQExitAutocall object at 0x000002467FE41A60&gt;" isContainer="True" isIPythonHidden="True" />
<var name="get_ipython" type="method" qualifier="builtins" value="%3Cbound method InteractiveShell.get_ipython of %3Cipykernel.zmqshell.ZMQInteractiveShell object at 0x000002467FDC8F40&gt;&gt;" isContainer="True" isIPythonHidden="True" />
<var name="init_weights" type="function" qualifier="builtins" value="%3Cfunction init_weights at 0x000002461F2BFAF0&gt;" isContainer="True" />
<var name="loss" type="CrossEntropyLoss" qualifier="torch.nn.modules.loss" value="CrossEntropyLoss%28%29" isContainer="True" />
<var name="net" type="Sequential" qualifier="torch.nn.modules.container" value="Sequential%28%0A  %280%29%3A Flatten%28start_dim=1%2C end_dim=-1%29%0A  %281%29%3A Linear%28in_features=784%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" shape="2" />
<var name="nn" type="module" qualifier="builtins" value="%3Cmodule %27torch.nn%27 from %27E%3A%5C%5Cana%5C%5Clib%5C%5Csite-packages%5C%5Ctorch%5C%5Cnn%5C%5C__init__.py%27&gt;" isContainer="True" />
<var name="num_epochs" type="int" qualifier="builtins" value="10" />
<var name="print_columns" type="function" qualifier="builtins" value="%3Cfunction print_columns at 0x000002461F2BF700&gt;" isContainer="True" />
<var name="pydev_jupyter_vars" type="module" qualifier="builtins" value="%3Cmodule %27pydev_jupyter_vars%27 from %27E%3A%5C%5CPyCharm 2021.3%5C%5Cplugins%5C%5Cpython%5C%5Chelpers-pro%5C%5Cjupyter_debug%5C%5Cpydev_jupyter_vars.py%27&gt;" isContainer="True" />
<var name="quit" type="ZMQExitAutocall" qualifier="IPython.core.autocall" value="%3CIPython.core.autocall.ZMQExitAutocall object at 0x000002467FE41A60&gt;" isContainer="True" isIPythonHidden="True" />
<var name="remove_imported_pydev_package" type="function" qualifier="builtins" value="%3Cfunction remove_imported_pydev_package at 0x000002467FE72C10&gt;" isContainer="True" />
<var name="sys" type="module" qualifier="builtins" value="%3Cmodule %27sys%27 %28built-in%29&gt;" isContainer="True" />
<var name="test_iter" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x000002461F920640&gt;" isContainer="True" shape="40" />
<var name="torch" type="module" qualifier="builtins" value="%3Cmodule %27torch%27 from %27E%3A%5C%5Cana%5C%5Clib%5C%5Csite-packages%5C%5Ctorch%5C%5C__init__.py%27&gt;" isContainer="True" />
<var name="train_iter" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x000002461F920760&gt;" isContainer="True" shape="235" />
<var name="trainer" type="SGD" qualifier="torch.optim.sgd" value="SGD %28%0AParameter Group 0%0A    dampening%3A 0%0A    lr%3A 0.1%0A    maximize%3A False%0A    momentum%3A 0%0A    nesterov%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="wandb" type="module" qualifier="builtins" value="%3Cmodule %27wandb%27 from %27E%3A%5C%5Cana%5C%5Clib%5C%5Csite-packages%5C%5Cwandb%5C%5C__init__.py%27&gt;" isContainer="True" />
</xml>